{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af4a797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3060\n",
      "Memory: 12.9GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31165c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
      "     ---------------------------------------- 0.0/803.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 803.2/803.2 kB 6.6 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting more-itertools (from openai-whisper)\n",
      "  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: numba in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai-whisper) (0.61.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai-whisper) (2.2.6)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Downloading tiktoken-0.12.0-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai-whisper) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from numba->openai-whisper) (0.44.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.11.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\пользователь\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
      "Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "Downloading tiktoken-0.12.0-cp313-cp313-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 879.1/879.1 kB 12.6 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml): started\n",
      "  Building wheel for openai-whisper (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=804013 sha256=a0aa9fef0accfe744544f5de6de24f71660fe7aae5be96bfceb645800bb3da4b\n",
      "  Stored in directory: c:\\users\\пользователь\\appdata\\local\\pip\\cache\\wheels\\ca\\58\\d5\\fb4539ad74c3ca81eb40f7eda020ac77d080b33ad57449d485\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: more-itertools, tiktoken, openai-whisper\n",
      "Successfully installed more-itertools-10.8.0 openai-whisper-20250625 tiktoken-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2295e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6af379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1.42G/1.42G [01:05<00:00, 23.3MiB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Whisper(\n",
       "  (encoder): AudioEncoder(\n",
       "    (conv1): Conv1d(80, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(1024, 1024, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (blocks): ModuleList(\n",
       "      (0-23): 24 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TextDecoder(\n",
       "    (token_embedding): Embedding(51865, 1024)\n",
       "    (blocks): ModuleList(\n",
       "      (0-23): 24 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper.load_model('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b9e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
